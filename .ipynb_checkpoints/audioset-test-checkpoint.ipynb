{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "swedish-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "SCENE=\"1\"\n",
    "CSV_FILE_PATH = \"./audioset_3sec_escena\"+SCENE+\".csv\"  # path of csv file\n",
    "DATA_PATH = \"./audioset_3sec_escena\"+SCENE+\"/\" # path to folde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "diagnostic-radar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vacuum00.2.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>aspirador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vacuum01.2.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>aspirador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vacuum010.2.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>aspirador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vacuum011.2.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>aspirador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vacuum012.2.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>aspirador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>doorbell058.2.wav</td>\n",
       "      <td>12</td>\n",
       "      <td>timbre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>doorbell06.2.wav</td>\n",
       "      <td>12</td>\n",
       "      <td>timbre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>doorbell07.2.wav</td>\n",
       "      <td>12</td>\n",
       "      <td>timbre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>doorbell08.2.wav</td>\n",
       "      <td>12</td>\n",
       "      <td>timbre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>doorbell09.2.wav</td>\n",
       "      <td>12</td>\n",
       "      <td>timbre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  target   category\n",
       "0       vacuum00.2.wav       1  aspirador\n",
       "1       vacuum01.2.wav       1  aspirador\n",
       "2      vacuum010.2.wav       1  aspirador\n",
       "3      vacuum011.2.wav       1  aspirador\n",
       "4      vacuum012.2.wav       1  aspirador\n",
       "..                 ...     ...        ...\n",
       "616  doorbell058.2.wav      12     timbre\n",
       "617   doorbell06.2.wav      12     timbre\n",
       "618   doorbell07.2.wav      12     timbre\n",
       "619   doorbell08.2.wav      12     timbre\n",
       "620   doorbell09.2.wav      12     timbre\n",
       "\n",
       "[621 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "particular-seeker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vacuum00.2.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>aspirador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>toilet_flush00.2.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>cisterna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>conversation00.2.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>conversacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>dishes_pots_and_pans00.2.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>cubiertos_sartenes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>alarm_clock00.2.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>despertador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>water00.2.wav</td>\n",
       "      <td>6</td>\n",
       "      <td>ducha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>water_tap00.2.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>grifo_cocina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>printer00.2.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>impresora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>microwave00.2.wav</td>\n",
       "      <td>9</td>\n",
       "      <td>microondas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>door00.2.wav</td>\n",
       "      <td>10</td>\n",
       "      <td>puerta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>telephone_bell_ringing00.2.wav</td>\n",
       "      <td>11</td>\n",
       "      <td>telefono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>doorbell00.2.wav</td>\n",
       "      <td>12</td>\n",
       "      <td>timbre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name  target            category\n",
       "0                    vacuum00.2.wav       1           aspirador\n",
       "52             toilet_flush00.2.wav       2            cisterna\n",
       "94             conversation00.2.wav       3        conversacion\n",
       "139    dishes_pots_and_pans00.2.wav       4  cubiertos_sartenes\n",
       "191             alarm_clock00.2.wav       5         despertador\n",
       "244                   water00.2.wav       6               ducha\n",
       "299               water_tap00.2.wav       7        grifo_cocina\n",
       "369                 printer00.2.wav       8           impresora\n",
       "420               microwave00.2.wav       9          microondas\n",
       "470                    door00.2.wav      10              puerta\n",
       "530  telephone_bell_ringing00.2.wav      11            telefono\n",
       "578                doorbell00.2.wav      12              timbre"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.drop_duplicates(subset=['target'])\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-professional",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "historical-blind",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " name        vacuum00.2.wav\n",
       " target                   1\n",
       " category         aspirador\n",
       " Name: 0, dtype: object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(220500,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2179cbe545c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0msig\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[0mmfcc_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mmfcc_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X , y = [] , []\n",
    "for data in tqdm(df.iterrows()):\n",
    "  data  \n",
    "  sig , sr = librosa.load(DATA_PATH+data[1][0])\n",
    "  sig.shape\n",
    "  mfcc_ = librosa.feature.mfcc(sig , sr=sr, n_mfcc=13)\n",
    "  mfcc_.shape\n",
    "  size=int(mfcc_.shape[1]/2)\n",
    "  size\n",
    "  mfcc_=mfcc_[:,size-65:size+65]\n",
    "  data[1][1] \n",
    "  mfcc_.shape\n",
    "  \n",
    "\n",
    "  if(mfcc_.shape != (13, 130)):\n",
    "        continue\n",
    "  X.append(mfcc_)\n",
    "  y.append(data[1][1])\n",
    "\n",
    "    \n",
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "def get_shape(lst, shape=()):\n",
    "    \"\"\"\n",
    "    returns the shape of nested lists similarly to numpy's shape.\n",
    "\n",
    "    :param lst: the nested list\n",
    "    :param shape: the shape up to the current recursion depth\n",
    "    :return: the shape including the current depth\n",
    "            (finally this will be the full depth)\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(lst, Sequence):\n",
    "        # base case\n",
    "        return shape\n",
    "\n",
    "    # peek ahead and assure all lists in the next depth\n",
    "    # have the same length\n",
    "    if isinstance(lst[0], Sequence):\n",
    "        l = len(lst[0])\n",
    "        if not all(len(item) == l for item in lst):\n",
    "            msg = 'not all lists have the same length'\n",
    "            raise ValueError(msg)\n",
    "\n",
    "    shape += (len(lst), )\n",
    "    \n",
    "    # recurse\n",
    "    shape = get_shape(lst[0], shape)\n",
    "\n",
    "    return shape\n",
    "\n",
    "\n",
    "print(get_shape(X))\n",
    "print(get_shape(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subjective-candy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fantastic-discovery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 13, 130, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(617, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# convert list to numpy array\n",
    "X = np.array(X) \n",
    "y = np.array(y)\n",
    "\n",
    "#one-hot encoding the target\n",
    "y = tf.keras.utils.to_categorical(y-1 , num_classes=12)\n",
    "\n",
    "# our tensorflow model takes input as (no_of_sample , height , width , channel).\n",
    "# here X has dimension (no_of_sample , height , width).\n",
    "# So, the below code will reshape it to (no_of_sample , height , width , 1).\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "X.shape\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "numerous-affiliation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46. 34. 44. 45. 50. 49. 61. 49. 43. 55. 44. 35.]\n",
      "[6. 8. 1. 7. 3. 6. 9. 2. 6. 4. 4. 6.]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 11, 128, 16)       160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 126, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 124, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 122, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 120, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 118, 256)       295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                12300     \n",
      "=================================================================\n",
      "Total params: 1,719,708\n",
      "Trainable params: 1,719,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_train , x_val , y_train , y_val = train_test_split(X , y ,test_size=0.1, random_state=1)\n",
    "\n",
    "\n",
    "print(np.sum(y_train, axis=0))\n",
    "print(np.sum(y_val, axis=0))\n",
    "\n",
    "\n",
    "INPUTSHAPE = (13,130,1)\n",
    "NUM_CLASSES=12\n",
    "\n",
    "model =  models.Sequential([\n",
    "                          layers.Conv2D(16 , (3,3),activation = 'relu',padding='valid', input_shape = INPUTSHAPE),\n",
    "                          layers.Conv2D(16, (3,3), activation='relu',padding='valid'),\n",
    "\n",
    "                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n",
    "                          layers.Conv2D(64, (3,3), activation='relu',padding='valid'),\n",
    "\n",
    "                          layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "                          layers.Conv2D(256, (3,3), activation='relu',padding='valid'),\n",
    "\n",
    "                          layers.GlobalAveragePooling2D(),\n",
    "\n",
    "\n",
    "                          layers.Dense(1024 , activation = 'relu'),\n",
    "                          layers.Dense(1024 , activation = 'relu'),\n",
    "    \n",
    "                          layers.Dense(NUM_CLASSES , activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'acc')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "younger-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "18/18 [==============================] - 3s 142ms/step - loss: 2.5509 - acc: 0.1396 - val_loss: 2.5379 - val_acc: 0.1935\n",
      "Epoch 2/40\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 2.2432 - acc: 0.2425 - val_loss: 2.5669 - val_acc: 0.2419\n",
      "Epoch 3/40\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 2.1185 - acc: 0.2727 - val_loss: 2.2826 - val_acc: 0.2742\n",
      "Epoch 4/40\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 2.0534 - acc: 0.2891 - val_loss: 2.2472 - val_acc: 0.2742\n",
      "Epoch 5/40\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 1.9818 - acc: 0.3021 - val_loss: 2.2789 - val_acc: 0.2419\n",
      "Epoch 6/40\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 1.9267 - acc: 0.3313 - val_loss: 2.3447 - val_acc: 0.2419\n",
      "Epoch 7/40\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 1.8132 - acc: 0.3446 - val_loss: 2.5332 - val_acc: 0.1935\n",
      "Epoch 8/40\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 1.7179 - acc: 0.4162 - val_loss: 2.4968 - val_acc: 0.2419\n",
      "Epoch 9/40\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 1.6527 - acc: 0.4106 - val_loss: 2.6499 - val_acc: 0.2419\n",
      "Epoch 10/40\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 1.5725 - acc: 0.4054 - val_loss: 2.5429 - val_acc: 0.2258\n",
      "Epoch 11/40\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 1.4869 - acc: 0.5042 - val_loss: 2.9181 - val_acc: 0.2419\n",
      "Epoch 12/40\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 1.4018 - acc: 0.4897 - val_loss: 2.5568 - val_acc: 0.2419\n",
      "Epoch 13/40\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 1.3969 - acc: 0.5569 - val_loss: 3.0139 - val_acc: 0.1452\n",
      "Epoch 14/40\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 1.4623 - acc: 0.5167 - val_loss: 2.5788 - val_acc: 0.3226\n",
      "Epoch 15/40\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 1.2964 - acc: 0.5480 - val_loss: 3.7210 - val_acc: 0.2097\n",
      "Epoch 16/40\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 1.1404 - acc: 0.5933 - val_loss: 3.5508 - val_acc: 0.2097\n",
      "Epoch 17/40\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 1.2354 - acc: 0.5862 - val_loss: 3.2734 - val_acc: 0.2419\n",
      "Epoch 18/40\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 1.0525 - acc: 0.6232 - val_loss: 3.7745 - val_acc: 0.1774\n",
      "Epoch 19/40\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 1.0452 - acc: 0.6250 - val_loss: 3.7009 - val_acc: 0.1613\n",
      "Epoch 20/40\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 1.0669 - acc: 0.6062 - val_loss: 3.9338 - val_acc: 0.2742\n",
      "Epoch 21/40\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 0.7839 - acc: 0.7190 - val_loss: 4.4499 - val_acc: 0.2097\n",
      "Epoch 22/40\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.7703 - acc: 0.7005 - val_loss: 5.4146 - val_acc: 0.2097\n",
      "Epoch 23/40\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 0.7733 - acc: 0.7363 - val_loss: 3.7128 - val_acc: 0.2097\n",
      "Epoch 24/40\n",
      "18/18 [==============================] - 2s 114ms/step - loss: 0.6231 - acc: 0.7623 - val_loss: 6.3633 - val_acc: 0.1613\n",
      "Epoch 25/40\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 0.5631 - acc: 0.7860 - val_loss: 6.7833 - val_acc: 0.2419\n",
      "Epoch 26/40\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 0.5183 - acc: 0.7954 - val_loss: 5.4540 - val_acc: 0.1613\n",
      "Epoch 27/40\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.6056 - acc: 0.7698 - val_loss: 5.1744 - val_acc: 0.1452\n",
      "Epoch 28/40\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.5050 - acc: 0.8161 - val_loss: 5.7479 - val_acc: 0.1613\n",
      "Epoch 29/40\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 0.4583 - acc: 0.8376 - val_loss: 5.2315 - val_acc: 0.2419\n",
      "Epoch 30/40\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 0.4537 - acc: 0.8301 - val_loss: 5.7133 - val_acc: 0.1774\n",
      "Epoch 31/40\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.6067 - acc: 0.7743 - val_loss: 5.5070 - val_acc: 0.2097\n",
      "Epoch 32/40\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.3698 - acc: 0.8746 - val_loss: 6.9278 - val_acc: 0.1452\n",
      "Epoch 33/40\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.5309 - acc: 0.8340 - val_loss: 6.0832 - val_acc: 0.1774\n",
      "Epoch 34/40\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.5441 - acc: 0.8250 - val_loss: 6.6240 - val_acc: 0.1935\n",
      "Epoch 35/40\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.3976 - acc: 0.8873 - val_loss: 6.5411 - val_acc: 0.2097\n",
      "Epoch 36/40\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.2794 - acc: 0.9024 - val_loss: 6.0240 - val_acc: 0.2097\n",
      "Epoch 37/40\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.3629 - acc: 0.8728 - val_loss: 7.7903 - val_acc: 0.2097\n",
      "Epoch 38/40\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 0.4057 - acc: 0.8645 - val_loss: 5.6510 - val_acc: 0.2097\n",
      "Epoch 39/40\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.4151 - acc: 0.8528 - val_loss: 5.8442 - val_acc: 0.1613\n",
      "Epoch 40/40\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.2407 - acc: 0.9060 - val_loss: 7.9495 - val_acc: 0.2258\n"
     ]
    }
   ],
   "source": [
    "LOGDIR = \"logs\"\n",
    "CPKT = \"cpkt/\"\n",
    "\n",
    "#this callback is used to prevent overfitting.\n",
    "callback_1 = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "#this checkpoint saves the best weights of model at every epoch\n",
    "callback_2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    CPKT, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "    save_weights_only=True, mode='auto', save_freq='epoch', options=None\n",
    ")\n",
    "\n",
    "#this is for tensorboard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOGDIR)\n",
    "\n",
    "\n",
    "history = model.fit(x_train,y_train ,\n",
    "            validation_data=(x_val,y_val),\n",
    "            epochs=40)\n",
    "# Guardar el Modelo\n",
    "model.save(\"model_audio_Escena\"+SCENE+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "weighted-requirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1 1 0 0 0 2 1 0 1 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 0 1 0 0 0 1 1]\n",
      " [0 0 0 3 0 1 3 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [3 1 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 1 0 1 0 0 0]\n",
      " [1 2 0 0 1 0 2 1 1 1 0 0]\n",
      " [0 0 1 0 0 1 0 0 1 2 0 0]\n",
      " [0 0 0 1 1 0 0 0 1 0 0 1]\n",
      " [1 0 0 0 1 1 1 1 1 0 2 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#Confution Matrix\n",
    "\n",
    "y_pred = np.argmax(model.predict(x_val),axis=1)\n",
    "print('Confusion Matrix')\n",
    "confusionMatrix = confusion_matrix(y_pred, np.argmax(y_val,axis=1))\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-broadway",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
